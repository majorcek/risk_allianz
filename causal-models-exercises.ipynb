{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples and exercises for causal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import xarray as xr\n",
    "\n",
    "#from graphviz import Digraph\n",
    "\n",
    "from brent import DAG, Query\n",
    "\n",
    "#from fake_data_for_learning import BayesianNodeRV, SampleValue, FakeDataBayesianNetwork\n",
    "#from fake_data_for_learning.utils import ProbabilityPolytope, ExpectationConstraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Jasa/Desktop/risk/risk-ai-workshop-master/notebooks/data')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = Path(os.getcwd()) / 'data'\n",
    "datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  3\n",
       "1  2  4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'a': [1, 2], 'b': [3,4]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal model example: hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5389, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>days</th>\n",
       "      <th>rating</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>property</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liability</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>financial</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liability</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liability</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type  days  rating  hit\n",
       "0     property     3       1    0\n",
       "1    liability     1       0    0\n",
       "2    financial     0       1    0\n",
       "3    liability     3       0    0\n",
       "4    liability     0       0    1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(datadir / 'hits.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = DAG(df).add_edge('product_type', 'rating').add_edge('product_type', 'days')\\\n",
    "    .add_edge('rating', 'hit').add_edge('days', 'hit')\n",
    "\n",
    "#dag.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_given = Query(dag).given(days=1)\n",
    "#dot = q_given.plot()\n",
    "#dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_do = Query(dag).do(days=1)\n",
    "#dot = q_do.plot()\n",
    "#dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_probs(inference_table, target_col, prob_col):\n",
    "    res = inference_table.loc[inference_table[target_col]==1, :]\n",
    "    return res[prob_col].sum()\n",
    "\n",
    "givens = []\n",
    "dos = []\n",
    "for days in range(0,4):\n",
    "    do_q = Query(dag).do(days=days)\n",
    "    do_prob = get_query_probs(do_q.infer(give_table=True), 'hit', 'prob')\n",
    "    dos.append(dict(days=days, prob=do_prob))\n",
    "    \n",
    "    given_q = Query(dag).given(days=days)\n",
    "    given_prob = get_query_probs(given_q.infer(give_table=True), 'hit', 'prob')\n",
    "    givens.append(dict(days=days, prob=given_prob))\n",
    "\n",
    "do_probs = pd.DataFrame(dos)\n",
    "given_probs = pd.DataFrame(givens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.548254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.445219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.293297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.205698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   days      prob\n",
       "0     0  0.548254\n",
       "1     1  0.445219\n",
       "2     2  0.293297\n",
       "3     3  0.205698"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "given_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.560296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.403429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.275838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.216522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   days      prob\n",
       "0     0  0.560296\n",
       "1     1  0.403429\n",
       "2     2  0.275838\n",
       "3     3  0.216522"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal models exercise: correlation\n",
    "\n",
    "Reproduce and try to break the spurious correlation between deaths by poisonous spider bites and the lenghts of winning words in the Scripps national spelling bee.\n",
    "\n",
    "The fatality data from the CDC can be found here: `notebooks/data/cdc-underlying-cause-of-death-1998-2018.txt`, and the spelling bee data can be found below.\n",
    "\n",
    "Difficulty: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://en.wiktionary.org/wiki/Appendix:Scripps_winning_words\n",
    "scripps_winners_raw = '''\n",
    "    1925: gladiolus\n",
    "    1926: abrogate\n",
    "    1927: luxuriance\n",
    "    1928: albumen\n",
    "    1929: asceticism\n",
    "    1930: fracas\n",
    "    1931: foulard\n",
    "    1932: knack\n",
    "    1933: torsion\n",
    "    1934: deteriorating\n",
    "    1935: intelligible\n",
    "    1936: interning\n",
    "    1937: promiscuous\n",
    "    1938: sanitarium\n",
    "    1939: canonical\n",
    "    1940: therapy\n",
    "    1941: initials\n",
    "    1942: sacrilegious\n",
    "\n",
    "The Bee was suspended during the WWII years of 1943â€“1945.\n",
    "\n",
    "    1946: semaphore\n",
    "    1947: chlorophyll\n",
    "    1948: psychiatry\n",
    "    1949: dulcimer\n",
    "    1950: meerschaum [1] / meticulosity\n",
    "    1951: insouciant\n",
    "    1952: vignette\n",
    "    1953: soubrette\n",
    "    1954: transept\n",
    "    1955: crustaceology\n",
    "    1956: condominium\n",
    "    1957: n/a [2]\n",
    "    1958: syllepsis\n",
    "    1959: catamaran\n",
    "    1960: eudaemonic\n",
    "    1961: smaragdine\n",
    "    1962: n/a [3]\n",
    "    1963: equipage\n",
    "    1964: sycophant\n",
    "    1965: eczema\n",
    "    1966: ratoon\n",
    "    1967: chihuahua\n",
    "    1968: abalone\n",
    "    1969: interlocutory\n",
    "    1970: croissant\n",
    "    1971: shalloon\n",
    "    1972: macerate\n",
    "\n",
    "    1973: vouchsafe\n",
    "    1974: hydrophyte\n",
    "    1975: incisor\n",
    "    1976: narcolepsy\n",
    "    1977: cambist\n",
    "    1978: deification\n",
    "    1979: maculature\n",
    "    1980: elucubrate\n",
    "    1981: sarcophagus\n",
    "    1982: psoriasis\n",
    "    1983: Purim\n",
    "    1984: luge\n",
    "    1985: milieu\n",
    "    1986: odontalgia\n",
    "    1987: staphylococci\n",
    "    1988: elegiacal\n",
    "    1989: spoliator\n",
    "    1990: fibranne\n",
    "    1991: antipyretic\n",
    "    1992: lyceum\n",
    "    1993: kamikaze\n",
    "    1994: antediluvian\n",
    "    1995: xanthosis\n",
    "    1996: vivisepulture\n",
    "    1997: euonym\n",
    "    1998: chiaroscurist\n",
    "    1999: logorrhea\n",
    "    2000: demarche\n",
    "    2001: succedaneum\n",
    "    2002: prospicience\n",
    "    2003: pococurante\n",
    "    2004: autochthonous\n",
    "    2005: appoggiatura\n",
    "    2006: Ursprache\n",
    "    2007: serrefine\n",
    "    2008: guerdon\n",
    "    2009: Laodicean\n",
    "    2010: stromuhr\n",
    "    2011: cymotrichous\n",
    "    2012: guetapens\n",
    "    2013: knaidel\n",
    "    2014: stichomythia / feuilleton\n",
    "    2015: scherenschnitte / nunatak\n",
    "    2016: Feldenkrais / gesellschaft\n",
    "    2017: marocain\n",
    "    2018: koinonia\n",
    "    2019: auslaut / erysipelas / bougainvillea [4] / aiguillette / pendeloque / palama / cernuous / odylic'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Deaths     Winning_Word  dolzina_zmagovalne\n",
      "0   1999     6.0        logorrhea                   9\n",
      "1   2000     5.0         demarche                   8\n",
      "2   2001     5.0      succedaneum                  11\n",
      "3   2002    10.0     prospicience                  12\n",
      "4   2003     8.0      pococurante                  11\n",
      "5   2004    14.0    autochthonous                  13\n",
      "6   2005    10.0     appoggiatura                  12\n",
      "7   2006     4.0        Ursprache                   9\n",
      "8   2007     8.0        serrefine                   9\n",
      "9   2008     5.0          guerdon                   7\n",
      "10  2009     6.0        Laodicean                   9\n",
      "11  2010     7.0         stromuhr                   8\n",
      "12  2011     3.0     cymotrichous                  12\n",
      "13  2012     7.0        guetapens                   9\n",
      "14  2013     7.0          knaidel                   7\n",
      "15  2014     7.0     stichomythia                  12\n",
      "16  2015     7.0  scherenschnitte                  15\n",
      "17  2016     5.0      Feldenkrais                  11\n",
      "18  2017     8.0         marocain                   8\n",
      "19  2018     4.0         koinonia                   8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson rho is 0.37880418441534974.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Jasa/Desktop/risk/risk-ai-workshop-master/notebooks/data/cdc-underlying-cause-of-death-1998-2018.txt', delimiter= '\\s+', header=0)\n",
    "data.head()\n",
    "\n",
    "## Data for deaths due to spiders bites\n",
    "indeksi = ['spider' in str(i) for i in data['Cause of death']]\n",
    "data_spider = data[indeksi]\n",
    "\n",
    "data_spider = data_spider[['Year', 'Deaths']]\n",
    "data_spider['Year'] = data_spider['Year'].astype('int64', copy=False)\n",
    "\n",
    "\n",
    "## Data for winning words\n",
    "\n",
    "data_winning_words = pd.DataFrame([x.split(':') for x in scripps_winners_raw.split('\\n')])\n",
    "data_winning_words.columns = [\"Year\", \"Winning_Word\"]\n",
    "\n",
    "pravi1 = ['1999' in str(i) for i in data_winning_words['Year']]\n",
    "pravi2 = ['20' in str(i) for i in data_winning_words['Year']]\n",
    "pravi = pd.DataFrame({'stolpec1': pravi1, 'stolpec2': pravi2})\n",
    "pravi['stolpec3'] = pravi[['stolpec1','stolpec2']].any(axis = 'columns')\n",
    "\n",
    "data_winning_words = data_winning_words[pravi['stolpec3']]\n",
    "\n",
    "prve_besede = []\n",
    "dolzine = []\n",
    "for i in data_winning_words['Winning_Word']:\n",
    "    prva = i.split()[0]\n",
    "    dolzina = len(prva)\n",
    "    prve_besede.append(prva)\n",
    "    dolzine.append(dolzina)\n",
    "\n",
    "data_winning_words = data_winning_words[['Year']]\n",
    "data_winning_words['Year'] = data_winning_words['Year'].astype('int64', copy=False)\n",
    "data_winning_words['Winning_Word'] = np.array(prve_besede)\n",
    "data_winning_words['dolzina_zmagovalne'] = np.array(dolzine)\n",
    "\n",
    "\n",
    "## Putting in one dataframe\n",
    "data_together = pd.merge(data_spider, data_winning_words, on = 'Year')\n",
    "print(data_together)\n",
    "\n",
    "\n",
    "plt.scatter(data_together['dolzina_zmagovalne'], data_together['Deaths'])\n",
    "plt.show()\n",
    "\n",
    "corr,_ = pearsonr(data_together['dolzina_zmagovalne'], data_together['Deaths'])\n",
    "print('Pearson rho is {}.'.format(corr))\n",
    "\n",
    "#print(np.array(data_together['dolzina_zmagovalne'].values), shuffle(data_together['Deaths']))\n",
    "#plt.scatter(np.array(data_together['dolzina_zmagovalne'].values), shuffle(data_together['Deaths']))\n",
    "#plt.show()\n",
    "#corr,_ = pearsonr(data_together['dolzina_zmagovalne'], shuffle(data_together['Deaths']))\n",
    "#print(corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal models exercise: do-calculus\n",
    "\n",
    "As before, take K to be your Karma, H to be the hours you spend in the gym lifting weight, and then W be the weight you can bench press. \n",
    "\n",
    "You are the parent of a very young child, so Karma will punish you for devoting too much time to your triceps and neglecting your partner and baby. Let $G$ be this causal graph, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot = Digraph(engine='neato')\n",
    "#dot.attr('node')\n",
    "#dot.node('K')\n",
    "#dot.node('H')\n",
    "#dot.node('W')\n",
    "\n",
    "#dot.edge('K', 'H')\n",
    "#dot.edge('K', 'W')\n",
    "#dot.edge('H', 'W')\n",
    "\n",
    "#dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Draw the graphs $G_\\underline{W}$ and $G_\\overline{H}$. Difficulty: *\n",
    "2. Write out formulas for $P(W=1 | H=1)$ and $P(W=1|\\, \\mathrm{do}(H) = 1)$. Difficulty: **\n",
    "\n",
    "3. Calculate $P(W=1 | H=1)$ and $P(W=1|\\, \\mathrm{do}(H) = 1)$ for a Bayesian network fitted to the sample data from $(K, H, W)$ in `notebooks/data/karma_weights.csv`. Hint: the `Query` class of [https://koaning.github.io/brent/](https://koaning.github.io/brent/) can be used. Interpret the results in a qualitative way, i.e. how do you think Karma should work in this situation? Difficulty: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal models exercise: Causal calculus\n",
    "\n",
    "Prove in gory detail that the special case of Causal rule 3 holds. Difficulty: *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
